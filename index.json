[{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/","section":"Darian's Blog","summary":"","title":"Darian's Blog"},{"content":"","date":null,"permalink":"/categories/lab-meetings/","section":"Categories","summary":"","title":"Lab Meetings"},{"content":"Make Code Run Fast # Here I provide some tips on how to make code run fast.\nProfile your code # Code profiling is a method that is used to detect how long each function or line of code takes to run and how often it gets executed.\nTiming code # In Jupyter Notebook we can use magic commands %%time and %timeit.\nimport time %%time time.sleep(1) CPU times: user 595 µs, sys: 1.02 ms, total: 1.61 ms Wall time: 1 s %timeit time.sleep(1) 1 s ± 1.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) Customize the number of runs with -r and the number of loops with -n.\n%timeit -n2 -r2 time.sleep(1) 1 s ± 128 µs per loop (mean ± std. dev. of 2 runs, 2 loops each) You can also use the module timeit inside a python script.\nimport timeit timeit.timeit(\u0026#39;time.sleep(0.1)\u0026#39;, number=4) a = 1 timeit.timeit(\u0026#34;a+a\u0026#34;, number=10000, globals=globals()) 0.000622792000285699 Profiling code # For complicated algorithm or code, it is better to use a profiler. The profiler will give you a more detailed report of the code execution.\nRprof and profvis for profiling R code # Rprof is a built-in profiler in R. It can be used to profile R code. The profvis package provides a visual interface for Rprof. These tools works better in RStudio.\n%%writefile profile_example.R profvis::profvis({ foo1 \u0026lt;- function(n){ return(sum((0:(n-1))^2)) } foo2 \u0026lt;- function(n){ ans \u0026lt;- 0 for (i in 0:(n-1)) { ans \u0026lt;- ans + i^2 } } foo3 \u0026lt;- function(n){ for (i in 1:10) { foo1(n) } foo2(n) } foo4 \u0026lt;- function(n){ for (i in 1:100) { foo2(n) } } work \u0026lt;- function(n){ foo1(n) foo2(n) foo3(n) foo4(n) } work(1e6) }) Overwriting profile_example.R cProfile for profiling Python code # cProfile is a profiler written in C for profiling Python code. The pstats module’s Stats class has a variety of methods for manipulating and printing the data saved into a profile results file. The snakeviz package provides a visual interface for cProfile.\nimport numpy as np def foo1(n): return np.sum(np.square(np.arange(n))) def foo2(n): return sum(i*i for i in range(n)) def foo3(n): [foo1(n) for i in range(10)] foo2(n) def foo4(n): return [foo2(n) for i in range(100)] def work(n): foo1(n) foo2(n) foo3(n) foo4(n) import cProfile import pstats pr = cProfile.Profile() pr.enable() work(int(1e6)) pr.disable() pr.dump_stats(\u0026#39;profile.prof\u0026#39;) # save the profile ps = pstats.Stats(pr).strip_dirs().sort_stats(\u0026#34;cumtime\u0026#34;) ps.print_stats() 102000470 function calls in 12.240 seconds Ordered by: cumulative time ncalls tottime percall cumtime percall filename:lineno(function) 2 0.000 0.000 12.240 6.120 interactiveshell.py:3472(run_code) 2 0.000 0.000 12.240 6.120 {built-in method builtins.exec} 1 0.000 0.000 12.240 12.240 588885064.py:1(\u0026lt;module\u0026gt;) 1 0.000 0.000 12.240 12.240 2834638900.py:16(work) 102 0.000 0.000 12.219 0.120 2834638900.py:6(foo2) 102 4.787 0.047 12.219 0.120 {built-in method builtins.sum} 1 0.000 0.000 11.922 11.922 2834638900.py:13(foo4) 1 0.000 0.000 11.922 11.922 2834638900.py:14(\u0026lt;listcomp\u0026gt;) 102000102 7.432 0.000 7.432 0.000 2834638900.py:7(\u0026lt;genexpr\u0026gt;) 1 0.000 0.000 0.134 0.134 2834638900.py:9(foo3) 11 0.010 0.001 0.021 0.002 2834638900.py:3(foo1) 1 0.000 0.000 0.013 0.013 2834638900.py:10(\u0026lt;listcomp\u0026gt;) 11 0.006 0.001 0.006 0.001 {built-in method numpy.arange} 11 0.000 0.000 0.004 0.000 \u0026lt;__array_function__ internals\u0026gt;:177(sum) 11 0.000 0.000 0.004 0.000 {built-in method numpy.core._multiarray_umath.implement_array_function} 11 0.000 0.000 0.004 0.000 fromnumeric.py:2188(sum) 11 0.000 0.000 0.004 0.000 fromnumeric.py:69(_wrapreduction) 11 0.004 0.000 0.004 0.000 {method 'reduce' of 'numpy.ufunc' objects} 2 0.000 0.000 0.000 0.000 codeop.py:117(__call__) 2 0.000 0.000 0.000 0.000 {built-in method builtins.compile} 2 0.000 0.000 0.000 0.000 contextlib.py:287(helper) 2 0.000 0.000 0.000 0.000 contextlib.py:104(__init__) 2 0.000 0.000 0.000 0.000 traitlets.py:692(__get__) 11 0.000 0.000 0.000 0.000 fromnumeric.py:70(\u0026lt;dictcomp\u0026gt;) 2 0.000 0.000 0.000 0.000 contextlib.py:141(__exit__) 4 0.000 0.000 0.000 0.000 {built-in method builtins.next} 2 0.000 0.000 0.000 0.000 contextlib.py:132(__enter__) 2 0.000 0.000 0.000 0.000 interactiveshell.py:1229(user_global_ns) 4 0.000 0.000 0.000 0.000 compilerop.py:180(extra_flags) 2 0.000 0.000 0.000 0.000 interactiveshell.py:3424(compare) 4 0.000 0.000 0.000 0.000 {built-in method builtins.getattr} 2 0.000 0.000 0.000 0.000 traitlets.py:654(get) 11 0.000 0.000 0.000 0.000 {built-in method builtins.isinstance} 11 0.000 0.000 0.000 0.000 fromnumeric.py:2183(_sum_dispatcher) 11 0.000 0.000 0.000 0.000 {method 'items' of 'dict' objects} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} \u0026lt;pstats.Stats at 0x10c8c0fd0\u0026gt; In shell run:\nsnakeviz profile.prof BLAS and LAPACK # BLAS (Basic Linear Algebra Subprograms) and LAPACK (Linear Algebra Package) are specifications that prescribe a set of low-level routines for performing common linear algebra operations They are used by many other softwares and packages, such as R, NumPy, SciPy, and scikit-learn.\nfrom threadpoolctl import threadpool_limits, threadpool_info,ThreadpoolController This numpy installed via pip by default rely on the OpenBLAS, one of the implementations of BLAS and LAPACK. Other implementations include Intel MKL and Apple Accelerate, etc.\nThe M2 chip has 8 cores and 8 threads. Half of the cores are performance cores and the other half are efficiency cores. 12-th and 13-th generation Intel chips also have performance cores and efficiency cores. Most AMD and Intel CPUs use hyperthreading to allow a single core to execute two threads simultaneously. The number of threads code use affect the performance a lot.\nthreadpool_info() [{'user_api': 'blas', 'internal_api': 'openblas', 'prefix': 'libopenblas', 'filepath': '/Users/dawang/Projects/lab_meeting/.venv/lib/python3.11/site-packages/numpy/.dylibs/libopenblas64_.0.dylib', 'version': '0.3.21', 'threading_layer': 'pthreads', 'architecture': 'armv8', 'num_threads': 8}] def mat_mul_8T(n): A = np.random.rand(100,100) B = np.random.rand(100,100) for i in range(n): np.matmul(A,B) %timeit mat_mul_8T(10000) 730 ms ± 90.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) controller = ThreadpoolController() @controller.wrap(limits=4,user_api=\u0026#39;blas\u0026#39;) def mat_mul_4T(n): A = np.random.rand(100,100) B = np.random.rand(100,100) for i in range(n): np.matmul(A,B) %timeit mat_mul_4T(10000) 173 ms ± 517 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) When using 4 threads, the matrix multiplication is about 3$\\times$ faster than using all 8 threads. The reason is that limiting the number of threads allows the M2 CPU to use the performance cores only, instead of waiting for the slow efficiency cores.\nFor AMD and Intel hyperthreading CPUs, using one thread per physical performance core is usually the fastest.\ncontroller = ThreadpoolController() @controller.wrap(limits=1,user_api=\u0026#39;blas\u0026#39;) def mat_mul_1T(n): A = np.random.rand(100,100) B = np.random.rand(100,100) for i in range(n): np.matmul(A,B) %timeit mat_mul_1T(10000) 482 ms ± 2.68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) Even turning off the multithreading for BLAS by limiting the number of thread to be 1 results in a speedup compared to using all 8 threads.\nChoosing the right BLAS and LAPACK implementation is also important. For example, the Intel MKL on Intel CPUs is usually faster than OpenBLAS. The Apple Accelerate on M1 and M2 chips is usually also faster than OpenBLAS.\nIn R, it is also possible to use alternative BLAS and LAPACK implementations. Please refer to the following links for more details.\nShort tutorial for setting up OpenBLAS in R for Windows\nUsing R with BLAS and LAPACK on WSL\nR package flexiblas for unix-like systems\nNumba and Cython # Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.\nThe first example of computing $\\pi$ using Monte Carlo comes from the website of Numba.\nfrom numba import njit import random def mc_pi(nsamples): acc = 0 for i in range(nsamples): x = random.random() y = random.random() if (x ** 2 + y ** 2) \u0026lt; 1.0: acc += 1 return 4.0 * acc / nsamples @njit def mc_pi_jit(nsamples): acc = 0 for i in range(nsamples): x = random.random() y = random.random() if (x ** 2 + y ** 2) \u0026lt; 1.0: acc += 1 return 4.0 * acc / nsamples %timeit mc_pi(1000000) 110 ms ± 2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) %timeit mc_pi_jit(1000000) 5.79 ms ± 2.82 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) The second example of Mandelbrot set comes from the documentation of Numba.\nPure python code is as follows:\n%matplotlib inline import matplotlib.pyplot as plt # color function for point at (x, y) def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j for i in range(max_iters): z = z*z + c if z.real*z.real + z.imag*z.imag \u0026gt;= 4: return i return max_iters def create_fractal(xmin, xmax, ymin, ymax, image, iters): height, width = image.shape pixel_size_x = (xmax - xmin)/width pixel_size_y = (ymax - ymin)/height for x in range(width): real = xmin + x*pixel_size_x for y in range(height): imag = ymin + y*pixel_size_y color = mandel(real, imag, iters) image[y, x] = color gimage = np.zeros((1024, 1536), dtype=np.uint8) xmin, xmax, ymin, ymax = np.array([-2.0, 1.0, -1.0, 1.0]).astype(\u0026#39;float32\u0026#39;) iters = 50 %timeit -r1 -n1 create_fractal(xmin, xmax, ymin, ymax, gimage, iters) plt.grid(False) plt.imshow(gimage, cmap=\u0026#39;jet\u0026#39;) pass 3.27 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) from numba import uint32, float32 Specifying the data type in a Numba function can speed up the code a lot.\nmandel_numba = njit(uint32(float32, float32, uint32))(mandel) @njit def create_fractal_numba(xmin, xmax, ymin, ymax, image, iters): height, width = image.shape pixel_size_x = (xmax - xmin)/width pixel_size_y = (ymax - ymin)/height for x in range(width): real = xmin + x*pixel_size_x for y in range(height): imag = ymin + y*pixel_size_y color = mandel_numba(real, imag, iters) image[y, x] = color gimage = np.zeros((1024, 1536), dtype=np.uint8) xmin, xmax, ymin, ymax = np.array([-2.0, 1.0, -1.0, 1.0]).astype(\u0026#39;float32\u0026#39;) iters = 50 %timeit -r1 -n1 create_fractal_numba(xmin, xmax, ymin, ymax, gimage, iters) plt.grid(False) plt.imshow(gimage, cmap=\u0026#39;jet\u0026#39;) 115 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) Cython is a superset of Python that compiles to C. It is a static compiler that requires type declarations. It is more difficult to use than Numba.\nUse built-in functions and proper libraries # We use an example of calculating the pairwise distance between a set of vectors to demonstrate the importance of using built-in functions.\nn = 100 p = 100 xs = np.random.random((n, p)) The most straightforward way is to use a nested loop. This is the slowest way.\ndef pdist_py(xs): \u0026#34;\u0026#34;\u0026#34;Unvectorized Python.\u0026#34;\u0026#34;\u0026#34; n, p = xs.shape A = np.zeros((n, n)) for i in range(n): for j in range(n): for k in range(p): A[i,j] += (xs[i, k] - xs[j, k])**2 A[i,j] = np.sqrt(A[i,j]) return A %timeit -r3 -n3 pdist_py(xs) 288 ms ± 7.94 ms per loop (mean ± std. dev. of 3 runs, 3 loops each) Since the pairwise distance is a symmetric matrix, we can only calculate the upper triangular part of the matrix and then copy the upper triangular part to the lower triangular part. This result in a 2$\\times$ speedup.\ndef pdist_py_sym(xs): \u0026#34;\u0026#34;\u0026#34;Unvectorized Python exploiting symmetry.\u0026#34;\u0026#34;\u0026#34; n, p = xs.shape A = np.zeros((n, n)) for i in range(n): for j in range(i+1,n): for k in range(p): A[i,j] += (xs[i, k] - xs[j, k])**2 A[i,j] = np.sqrt(A[i,j]) A += A.T return A %timeit -r3 -n3 pdist_py_sym(xs) 142 ms ± 1.99 ms per loop (mean ± std. dev. of 3 runs, 3 loops each) The distance between two vectors can be calculated by the numpy.linalg.norm function. This result in a large speedup.\ndef pdist_vec(xs): \u0026#34;\u0026#34;\u0026#34;Vectorized inner loop using numpy.\u0026#34;\u0026#34;\u0026#34; n, p = xs.shape A = np.zeros((n, n)) for i in range(n): for j in range(i+1,n): A[i,j] = np.linalg.norm(xs[i,:] - xs[j,:]) A += A.T return A %timeit -r3 -n3 pdist_vec(xs) 7.45 ms ± 314 µs per loop (mean ± std. dev. of 3 runs, 3 loops each) Further more, the two-layer loop can be replaced by a numpy broadcasting operation.\ndef pdist_np(xs): \u0026#34;\u0026#34;\u0026#34;Fully vectorized using numpy.\u0026#34;\u0026#34;\u0026#34; return np.sqrt(np.sum((xs[:,None,:] - xs[None,:,:])**2, axis=-1)) %timeit -r30 -n30 pdist_np(xs) 1.25 ms ± 48.2 µs per loop (mean ± std. dev. of 30 runs, 30 loops each) Also, we can use the JIT techneque to speed up the code.\npdist_numba = njit(pdist_py_sym, cache = True) %timeit -r30 -n30 pdist_numba(xs) The slowest run took 15.81 times longer than the fastest. This could mean that an intermediate result is being cached. 428 µs ± 757 µs per loop (mean ± std. dev. of 30 runs, 30 loops each) However, the fastest way is to use the scipy.spatial.distance.pdist function.\nfrom scipy.spatial.distance import pdist, squareform %timeit -r30 -n30 squareform(pdist(xs)) 128 µs ± 3.45 µs per loop (mean ± std. dev. of 30 runs, 30 loops each) Let\u0026rsquo;s check whether the results are the same.\nnp.allclose(pdist_np(xs), squareform(pdist(xs))) True Another example is to calculate the matrix multiplication. The numpy.dot function and the @ operator are most frequently used. But sometimes the torch library is faster.\nimport torch A = np.random.random((1000, 1000)) B = np.random.random((1000, 1000)) %timeit -r10 -n10 np.dot(A, B) %timeit -r10 -n10 A @ B %timeit -r10 -n10 np.matmul(A, B) 23.7 ms ± 2.65 ms per loop (mean ± std. dev. of 10 runs, 10 loops each) 24.2 ms ± 2.54 ms per loop (mean ± std. dev. of 10 runs, 10 loops each) 23.9 ms ± 1.91 ms per loop (mean ± std. dev. of 10 runs, 10 loops each) torch_A = torch.from_numpy(A) torch_B = torch.from_numpy(B) %timeit -r10 -n10 torch.matmul(torch_A, torch_B) 8.07 ms ± 2.26 ms per loop (mean ± std. dev. of 10 runs, 10 loops each) cpp in Python and R # Todo\u0026hellip;\nSources # pybind11\ncppimport\nEigen\nArmadillo\nRcpp\nRcppArmadillo\nRcppEigen\nParallel computing # Todo\u0026hellip;\n","date":"1 June 2023","permalink":"/posts/make_code_run_fast/","section":"Posts","summary":"Here I provide some tips on how to make code run fast.","title":"Make Code Run Fast"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/programming/","section":"Tags","summary":"","title":"Programming"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"这几天把个人博客搭了起来，记录一下过程。\n起因 # 其实一直想搭一个博客玩玩，之前其实也有试过用 hexo ，并且部署在放在学校的一台电脑上，但没有固定 ip 并且只为了一个静态网站一直开着电脑也有点浪费（其实并不，是一台装了 pve 的主机，还运行着 nas 等服务）。主要原因还是没什么东西可写，所以上一个域名过期后就不了了之了。\n前段时间用学生邮箱申请了一个微软的 Azure 免费账户，主要是想免费用它提供的虚拟机。（微软对大陆的 .edu.cn 邮箱好像非常严格，尝试直接验证和 GitHub student developer pack 认证都不行，最后和客服邮件+电话扯了一周才注册成功。）然后偶然看到 Azure 也可以部署 static web apps ，就想试用一下。当然还有很多类似的服务提供商，比如 GitHub pages, Vercel, Netlify等等。\n域名 # 同样是用学生邮箱在 Namecheap 注册的免费 .me 域名，不过一年后应该就要续费了。\n网站生成工具：Hugo # ","date":"19 April 2023","permalink":"/posts/building_the_blog/","section":"Posts","summary":"","title":"记录个人博客搭建：使用Hugo以及Congo主题"},{"content":" 暂时只配置了 Canokey 的 PGP 密钥，包括签名、认证和加密。其中签名密钥用来给 git 的commit签名。 测试一下 GitHub 新的commit是否显示 verified。\n你可以在 这里 找到我的PGP公钥。\ngpg -expert --full-gen-key gpg --quick-add-key 1548C03A3741D936 cv25519 encr gpg --quick-add-key 1548C03A3741D936 ed25519 sign gpg --quick-add-key 1548C03A3741D936 ed25519 auth gpg -ao ppg-key.pub --export 1548C03A3741D936 gpg -ao sec-key.asc --export-private-key 1548C03A3741D936! gpg -ao encr-key.asc --export-private-key \u0026lt;fingerprint\u0026gt;! gpg -ao sign-key.asc --export-private-key \u0026lt;fingerprint\u0026gt;! gpg -ao auth-key.asc --export-private-key \u0026lt;fingerprint\u0026gt;! gpg --edit-key 1548C03A3741D936 gpg/key\u0026gt; 1 gpg/key\u0026gt; keytocard gpg --edit-card gpg/card\u0026gt; fetch git config --global user.signingkey 1548C03A3741D936 git commit -S -m \u0026#34;This commit is signed with my PGP key.\u0026#34; ","date":"18 April 2023","permalink":"/posts/learning_to_use_gnugpg_and_canokey/","section":"Posts","summary":"你可以在这里找到我的PGP公钥。","title":"使用 PGP 和 Canokey"},{"content":" Darian Wang (王达) # I am a PhD student at Center for Statistical Sciences, Tsinghua University.\nMy PGP key fingerprint is FB95 1601 3547 40FD 3BFF FA54 18DA FD16 E108 DDC9.\nMy research interests include\nStatistical computing Bayesian statistics Markov Chain Monte Carlo Statistical Machine Learning False Discovery Rate Education # Ph.D Statistics, Tsinghua University, 2020-now B.S. Mathematics, Tsinghua University, 2016-2020 Publications # Errr\u0026hellip;.. No publications yet.\nTeaching # 2020 Fall: Statistical Inference (undergraduate, TA) 2020 Spring: Introduction to Statistics: the Science and Art of Data Analysis (undergraduate, TA) 2021 Fall: Statistical Inference (undergraduate, TA) 2021 Spring: Advanced Statistical Computing (graduate, TA) ","date":"15 April 2023","permalink":"/about/","section":"Darian's Blog","summary":"Darian Wang (王达) # I am a PhD student at Center for Statistical Sciences, Tsinghua University.","title":"About Me"},{"content":"","date":null,"permalink":"/categories/development/","section":"Categories","summary":"","title":"Development"},{"content":"","date":null,"permalink":"/categories/test/","section":"Categories","summary":"","title":"test"},{"content":"","date":null,"permalink":"/tags/%E5%8D%9A%E5%AE%A2/","section":"Tags","summary":"","title":"博客"},{"content":"","date":null,"permalink":"/tags/%E6%B5%8B%E8%AF%95%E7%94%A8/","section":"Tags","summary":"","title":"测试用"},{"content":"This post is a test post.\nHAHA # 测试 # 3rd level # 4th level # 5th level # 测试一下哦 测试一下哦 New article! Call to action \\(f(a,b,c) = (a^2+b^2+c^2)^3\\)\nTest Test test \\(\\alpha\\) $$ \\beta $$ [1]/[2]\nWarning! This action is destructive! def add(a,b): return a+b 😂\n","date":"15 April 2023","permalink":"/posts/first_post/","section":"Posts","summary":"测试summary","title":"第一篇测试"}]